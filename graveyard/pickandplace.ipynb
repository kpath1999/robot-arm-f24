{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Robot Pick-and-Place Environment\n",
        "\n",
        "1. **`PickAndPlaceEnv` Class:** This is the main class that defines the robot pick and place environment.\n",
        "\n",
        "2. **Action and Observation Spaces:** Defines the structure of actions and observations for the environment.\n",
        "\n",
        "3. **PyBullet Initialization:** Sets up the PyBullet physics simulation environment.\n",
        "\n",
        "4. **Load Environment Components:** Loads the necessary objects (plane, robot, and cube) into the simulation.\n",
        "\n",
        "5. **Robot Configuration:** Specifies the robot's end-effector and gripper joint indices.\n",
        "\n",
        "6. **Reset Method:** Resets the environment to its initial state.\n",
        "\n",
        "7. **Observation Method:** Collects and returns the current state of the environment.\n",
        "\n",
        "8. **Step Method:** Executes an action in the environment and returns the new state, reward, and other information.\n",
        "\n",
        "9. **Reward Computation:** Calculates the reward based on the robot's performance.\n",
        "\n",
        "10. **Rendering Method:** Configures the PyBullet visualizer when GUI mode is enabled.\n",
        "\n",
        "11. **Cleanup Method:** Disconnects from the PyBullet server when the environment is closed.\n",
        "\n",
        "12. **Environment Checker:** Uses the Stable Baselines 3 library to verify that the environment is correctly implemented."
      ],
      "metadata": {
        "id": "kyaBsZ6oo1dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pybullet --quiet"
      ],
      "metadata": {
        "id": "sWwirgefv4DI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra] --quiet"
      ],
      "metadata": {
        "id": "R7Yh7mR46Ida"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC3i3_9qFgtP",
        "outputId": "f36cecc3-1f64-4ae6-8df1-237be223f6cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nEjfN_fElud2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c572928-a16b-402b-a9bb-d9e77b0bb609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pybullet as p\n",
        "import pybullet_data\n",
        "import time\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def check_file_exists(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"File exists: {file_path}\")\n",
        "    else:\n",
        "        print(f\"File does not exist: {file_path}\")\n",
        "\n",
        "# List of URDF files to check\n",
        "urdf_files = [\n",
        "    \"/content/drive/My Drive/MSCS/AdvML/urdf_files/plane.urdf\",\n",
        "    \"/content/drive/My Drive/MSCS/AdvML/urdf_files/franka_panda/panda.urdf\",\n",
        "    \"/content/drive/My Drive/MSCS/AdvML/urdf_files/cube_small.urdf\"\n",
        "]\n",
        "\n",
        "# Check each file\n",
        "for file in urdf_files:\n",
        "    check_file_exists(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-dcubimEZjI",
        "outputId": "43d0640c-1d12-4dd1-d595-b8b87482afb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: /content/drive/My Drive/MSCS/AdvML/urdf_files/plane.urdf\n",
            "File exists: /content/drive/My Drive/MSCS/AdvML/urdf_files/franka_panda/panda.urdf\n",
            "File exists: /content/drive/My Drive/MSCS/AdvML/urdf_files/cube_small.urdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the PickAndPlaceEnv Class"
      ],
      "metadata": {
        "id": "tPdxn-kOwBd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PickAndPlaceEnv(gym.Env):\n",
        "    metadata = {'render.modes' : ['human']}\n",
        "\n",
        "    def __init__(self, GUI=False):\n",
        "        super(PickAndPlaceEnv, self).__init__()\n",
        "\n",
        "        # Define action space: [delta_x, delta_y, delta_z, gripper_action]\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(4,), dtype=np.float32)\n",
        "\n",
        "        # Define observation space: [ee_x, ee_y, ee_z, obj_x, obj_y, obj_z, gripper_state]\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(7,), dtype=np.float32)\n",
        "\n",
        "        # Connect to the PyBullet physics server\n",
        "        if not GUI:\n",
        "            self.physics_client = p.connect(p.DIRECT)  # Use DIRECT mode for headless rendering\n",
        "        else:\n",
        "            self.physics_client = p.connect(p.GUI)     # GUI mode for visualization\n",
        "\n",
        "        self.GUI = GUI\n",
        "\n",
        "        # Set up PyBullet environment\n",
        "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "        p.setGravity(0, 0, -9.81)\n",
        "\n",
        "        # Load plane, robot and object\n",
        "        self.plane_id = p.loadURDF(\"plane.urdf\")\n",
        "        self.robot_id = p.loadURDF(\"franka_panda/panda.urdf\", [0, 0, 0], p.getQuaternionFromEuler([0,0,0]))\n",
        "        self.object_id = p.loadURDF(\"cube_small.urdf\", [0.5, 0, 0.05])\n",
        "\n",
        "        # Identify end-effector and gripper joints\n",
        "        self.ee_link_index = 11                 # Index of the end-effector link in the robot's URDF\n",
        "        self.gripper_joint_indices = [9, 10]    # Gripper joint indices for Franka Panda\n",
        "\n",
        "    def reset(self, seed=None, **kwargs):\n",
        "        # Reset simulation and reload objects\n",
        "        p.resetSimulation()\n",
        "        p.setGravity(0, 0, -9.81)\n",
        "        self.plane_id = p.loadURDF(\"plane.urdf\")\n",
        "        self.robot_id = p.loadURDF(\"franka_panda/panda.urdf\", [0, 0, 0], p.getQuaternionFromEuler([0,0,0]))\n",
        "        self.object_id = p.loadURDF(\"cube_small.urdf\", [0.5, 0, 0.05])\n",
        "\n",
        "        # Reset robot joints to initial position\n",
        "        num_joints = p.getNumJoints(self.robot_id)\n",
        "        for joint in range(num_joints):\n",
        "            p.resetJointState(self.robot_id, joint, 0)\n",
        "\n",
        "        # Return initial observation\n",
        "        return self.get_obs(), {}\n",
        "\n",
        "    def get_obs(self):\n",
        "        # Get end-effector position\n",
        "        ee_state = p.getLinkState(self.robot_id, self.ee_link_index)\n",
        "        ee_pos = ee_state[4]\n",
        "\n",
        "        # Get object position\n",
        "        obj_pos, _ = p.getBasePositionAndOrientation(self.object_id)\n",
        "\n",
        "        # Get gripper state (open or closed)\n",
        "        gripper_states = [p.getJointState(self.robot_id, idx)[0] for idx in self.gripper_joint_indices]\n",
        "        gripper_closed = 1.0 if sum(gripper_states) > 0 else 0.0\n",
        "\n",
        "        # Combine all observations\n",
        "        observation = np.array(list(ee_pos) + list(obj_pos) + [gripper_closed], dtype=np.float32)\n",
        "\n",
        "        return observation\n",
        "\n",
        "    def step(self, action):\n",
        "        truncated = False\n",
        "        try:\n",
        "            # Scale and apply actions\n",
        "            delta_pos = action[:3] * 0.05           # Scale movement\n",
        "            gripper_action = (action[3] + 1) / 2    # Scale gripper action from [-1,1] to [0,1]\n",
        "\n",
        "            # Get current end-effector position\n",
        "            ee_state = p.getLinkState(self.robot_id, self.ee_link_index)\n",
        "            current_pos = np.array(ee_state[4])\n",
        "            target_pos = current_pos + delta_pos\n",
        "\n",
        "            # Calculate inverse kinematics\n",
        "            joint_angles = p.calculateInverseKinematics(self.robot_id, self.ee_link_index, target_pos)\n",
        "\n",
        "            # Apply joint angles to robot\n",
        "            for i, angle in enumerate(joint_angles):\n",
        "                p.setJointMotorControl2(bodyIndex=self.robot_id, jointIndex=i,\n",
        "                                        controlMode=p.POSITION_CONTROL,\n",
        "                                        targetPosition=angle, force=500)\n",
        "\n",
        "            # Step simulation\n",
        "            p.stepSimulation()\n",
        "\n",
        "            # Get new observation\n",
        "            obs = self.get_obs()\n",
        "\n",
        "            # Compute reward and check if done\n",
        "            reward, done = self._compute_reward(obs)\n",
        "\n",
        "        except:\n",
        "            # Handle exceptions (e.g., inverse kinematics failure)\n",
        "            truncated = True\n",
        "            obs = self.get_obs()\n",
        "            reward = -100\n",
        "            done = False\n",
        "\n",
        "        return obs, reward, done, truncated, {}\n",
        "\n",
        "    def _compute_reward(self):\n",
        "        # Define target position\n",
        "        target_pos = np.array([0.6, 0, 0.05])   # Example target position\n",
        "\n",
        "        # Get current object position\n",
        "        obj_pos, _ = p.getBasePositionAndOrientation(self.object_id)\n",
        "\n",
        "        # Calculate distance to target\n",
        "        distance = np.linalg.norm(np.array(obj_pos[:3] - target_pos))\n",
        "\n",
        "        # Compute reward and check for task completion\n",
        "        reward = -distance          # Negative distance as reward\n",
        "        done = False\n",
        "        success_threshold = 0.02    # Distance threshold for success\n",
        "\n",
        "        if distance < success_threshold:\n",
        "            reward += 100           # Bonus reward for successful placement\n",
        "            done = True\n",
        "\n",
        "        return reward, done\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        if self.GUI:\n",
        "            p.configureDebugVisualizer(p.COV_ENABLE_GUI, 1)\n",
        "            p.configureDebugVisualizer(p.COV_ENABLE_RGB_BUFFER_PREVIEW, 1)\n",
        "            p.configureDebugVisualizer(p.COV_ENABLE_DEPTH_BUFFER_PREVIEW, 1)\n",
        "            p.configureDebugVisualizer(p.COV_ENABLE_SEGMENTATION_MARK_PREVIEW, 1)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def close(self):\n",
        "        p.disconnect()"
      ],
      "metadata": {
        "id": "pIFgucARvquE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = PickAndPlaceEnv()\n",
        "check_env(env)"
      ],
      "metadata": {
        "id": "zt-QOcar6B1C"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}