{"cells":[{"cell_type":"markdown","metadata":{"id":"Gl6HiK_IJh6H"},"source":["# Kuka\n","\n","---\n","\n","You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n","\n","### Start the Environment\n"]},{"cell_type":"markdown","metadata":{"id":"z9qRzdfsJh6K"},"source":["Make sure that you're in the right virtual environment and the right python version."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8846,"status":"ok","timestamp":1731700949395,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":300},"id":"3ojo0kXpJh6K","outputId":"c53d1faf-379f-4fa5-b0df-ad5a99ad2470"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n","Collecting pybullet\n","  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybullet\n","Successfully installed pybullet-3.2.6\n"]}],"source":["!python --version\n","!pip install pybullet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5626,"status":"ok","timestamp":1731700955017,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":300},"id":"l93HutNiJh6M","outputId":"0545534e-8135-4817-c79a-be53cde4d3c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["current_dir=/usr/local/lib/python3.10/dist-packages/pybullet_envs/bullet\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n","  logger.warn(\n"]}],"source":["import matplotlib.pyplot as plt\n","import sys\n","from collections import deque\n","import timeit\n","from datetime import timedelta\n","from copy import deepcopy\n","import numpy as np\n","import random\n","import time\n","import os\n","import csv\n","import logging\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import torch.optim as optim\n","\n","from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n","from gym import spaces\n","import pybullet as p\n","\n","env = KukaDiverseObjectEnv(renders=False, isDiscrete=False, removeHeightHack=False, maxSteps=20)\n","env.cid = p.connect(p.DIRECT)\n","action_space = spaces.Box(low=-1, high=1, shape=(5,1))\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["# add logging capabilties\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","write_to = '/content/drive/My Drive/MSCS/AdvML/ppo/logs'\n","os.makedirs(write_to, exist_ok=True)\n","\n","log_file = os.path.join(write_to, f'ppo_log_{time.strftime(\"%Y%m%d-%H%M%S\")}.csv')\n","logging.basicConfig(filename=log_file, level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","# Ensure CSV file has headers\n","if not os.path.exists(log_file):\n","    with open(log_file, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([\"Season\", \"Episode Reward\", \"Mean Reward (last 100)\", \"Epsilon\", \"Beta\", \"Clip Loss\", \"Value Loss\", \"Entropy\", \"Total Loss\"])\n","\n","def log_metrics(season, episode_reward, mean_reward, epsilon, beta, clip_loss, value_loss, entropy, total_loss):\n","    # Write metrics to CSV log\n","    with open(log_file, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([season, episode_reward, mean_reward, epsilon, beta, clip_loss, value_loss, entropy, total_loss])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mIJEsGKlCeh3","executionInfo":{"status":"ok","timestamp":1731700984940,"user_tz":300,"elapsed":29933,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"}},"outputId":"6334f1d7-f1e6-4456-cbf4-5420998b229c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"9zxPoSQEJh6N"},"source":["Actor-Critic implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ANrsV3bJh6N"},"outputs":[],"source":["def build_hidden_layer(input_dim, hidden_layers):\n","    \"\"\"Build hidden layer.\n","    Params\n","    ======\n","        input_dim (int): Dimension of hidden layer input\n","        hidden_layers (list(int)): Dimension of hidden layers\n","    \"\"\"\n","    hidden = nn.ModuleList([nn.Linear(input_dim, hidden_layers[0])])\n","    if len(hidden_layers)>1:\n","        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n","        hidden.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n","    return hidden\n","\n","class ActorCritic(nn.Module):\n","    def __init__(self,state_size,action_size,shared_layers,\n","                 critic_hidden_layers=[],actor_hidden_layers=[],\n","                 seed=0, init_type=None):\n","        \"\"\"Initialize parameters and build policy.\n","        Params\n","        ======\n","            state_size (int,int,int): Dimension of each state\n","            action_size (int): Dimension of each action\n","            shared_layers (list(int)): Dimension of the shared hidden layers\n","            critic_hidden_layers (list(int)): Dimension of the critic's hidden layers\n","            actor_hidden_layers (list(int)): Dimension of the actor's hidden layers\n","            seed (int): Random seed\n","            init_type (str): Initialization type\n","        \"\"\"\n","        super(ActorCritic, self).__init__()\n","        self.init_type = init_type\n","        self.seed = torch.manual_seed(seed)\n","        self.sigma = nn.Parameter(torch.zeros(action_size))\n","\n","        # Add shared hidden layer\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        # Number of Linear input connections depends on output of conv2d layers\n","        # and therefore the input image size, so compute it.\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(state_size[0])))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(state_size[1])))\n","        linear_input_size = convh * convw * 32\n","        self.shared_layers = build_hidden_layer(input_dim=linear_input_size,\n","                                                hidden_layers=shared_layers)\n","\n","        # Add critic layers\n","        if critic_hidden_layers:\n","            # Add hidden layers for critic net if critic_hidden_layers is not empty\n","            self.critic_hidden = build_hidden_layer(input_dim=shared_layers[-1],\n","                                                    hidden_layers=critic_hidden_layers)\n","            self.critic = nn.Linear(critic_hidden_layers[-1], 1)\n","        else:\n","            self.critic_hidden = None\n","            self.critic = nn.Linear(shared_layers[-1], 1)\n","\n","        # Add actor layers\n","        if actor_hidden_layers:\n","            # Add hidden layers for actor net if actor_hidden_layers is not empty\n","            self.actor_hidden = build_hidden_layer(input_dim=shared_layers[-1],\n","                                                   hidden_layers=actor_hidden_layers)\n","            self.actor = nn.Linear(actor_hidden_layers[-1], action_size)\n","        else:\n","            self.actor_hidden = None\n","            self.actor = nn.Linear(shared_layers[-1], action_size)\n","\n","        # Apply Tanh() to bound the actions\n","        self.tanh = nn.Tanh()\n","\n","        # Initialize hidden and actor-critic layers\n","        if self.init_type is not None:\n","            self.shared_layers.apply(self._initialize)\n","            self.critic.apply(self._initialize)\n","            self.actor.apply(self._initialize)\n","            if self.critic_hidden is not None:\n","                self.critic_hidden.apply(self._initialize)\n","            if self.actor_hidden is not None:\n","                self.actor_hidden.apply(self._initialize)\n","\n","    def _initialize(self, n):\n","        \"\"\"Initialize network weights.\n","        \"\"\"\n","        if isinstance(n, nn.Linear):\n","            if self.init_type=='xavier-uniform':\n","                nn.init.xavier_uniform_(n.weight.data)\n","            elif self.init_type=='xavier-normal':\n","                nn.init.xavier_normal_(n.weight.data)\n","            elif self.init_type=='kaiming-uniform':\n","                nn.init.kaiming_uniform_(n.weight.data)\n","            elif self.init_type=='kaiming-normal':\n","                nn.init.kaiming_normal_(n.weight.data)\n","            elif self.init_type=='orthogonal':\n","                nn.init.orthogonal_(n.weight.data)\n","            elif self.init_type=='uniform':\n","                nn.init.uniform_(n.weight.data)\n","            elif self.init_type=='normal':\n","                nn.init.normal_(n.weight.data)\n","            else:\n","                raise KeyError('initialization type is not found in the set of existing types')\n","\n","    def forward(self, state):\n","        \"\"\"Build a network that maps state -> (action, value).\"\"\"\n","        def apply_multi_layer(layers,x,f=F.leaky_relu):\n","            for layer in layers:\n","                x = f(layer(x))\n","            return x\n","\n","        state = F.relu(self.bn1(self.conv1(state)))\n","        state = F.relu(self.bn2(self.conv2(state)))\n","        state = F.relu(self.bn3(self.conv3(state)))\n","        state = apply_multi_layer(self.shared_layers,state.view(state.size(0),-1))\n","\n","        v_hid = state\n","        if self.critic_hidden is not None:\n","            v_hid = apply_multi_layer(self.critic_hidden,v_hid)\n","\n","        a_hid = state\n","        if self.actor_hidden is not None:\n","            a_hid = apply_multi_layer(self.actor_hidden,a_hid)\n","\n","        a = self.tanh(self.actor(a_hid))\n","        value = self.critic(v_hid).squeeze(-1)\n","        return a, value"]},{"cell_type":"markdown","metadata":{"id":"T89naFAaJh6O"},"source":["Examine the state and action spaces."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"elapsed":1580,"status":"ok","timestamp":1731700986515,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":300},"id":"CtDJk7ECJh6O","outputId":"44d45696-1514-4e9f-d7c1-496e238f789a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of agents: 1\n","Size of each action: 3\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(40, interpolation=Image.BICUBIC),\n","                    T.ToTensor()])\n","\n","def get_screen():\n","    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n","    # such as 800x1200x3. Transpose it into torch order (CHW).\n","    #env.render(mode='human')\n","    screen = env._get_observation().transpose((2, 0, 1))\n","    # Convert to float, rescale, convert to torch tensor\n","    # (this doesn't require a copy)\n","    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n","    screen = torch.from_numpy(screen)\n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0).to(device)\n","\n","\n","env.reset()\n","\n","# number of agents\n","num_agents = 1\n","print('Number of agents:', num_agents)\n","\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","# size of each action\n","action_size = env.action_space.shape[0]\n","print('Size of each action:', action_size)\n","\n","plt.figure()\n","plt.imshow(init_screen.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQVf5JpeJh6O"},"outputs":[],"source":["i_episode = 0\n","ten_rewards = 0\n","def collect_trajectories(envs, policy, tmax=200, nrand=5):\n","\n","    global i_episode\n","    global ten_rewards\n","    # global writer\n","\n","    #initialize returning lists and start the game!\n","    state_list=[]\n","    reward_list=[]\n","    prob_list=[]\n","    action_list=[]\n","    value_list=[]\n","    done_list=[]\n","\n","    state = envs.reset()\n","\n","    # perform nrand random steps\n","    for _ in range(nrand):\n","        action = np.random.randn(action_size)\n","        action = np.clip(action, -1.0, 1.0)\n","        _, reward, done, _  = envs.step(action)\n","        reward = torch.tensor([reward], device=device)\n","\n","    for t in range(tmax):\n","        states = get_screen()\n","        action_est, values = policy(states)\n","        sigma = nn.Parameter(torch.zeros(action_size))\n","        dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n","        actions = dist.sample()\n","        log_probs = dist.log_prob(actions)\n","        log_probs = torch.sum(log_probs, dim=-1).detach()\n","        values = values.detach()\n","        actions = actions.detach()\n","\n","        env_actions = actions.cpu().numpy()\n","        _, reward, done, _  = envs.step(env_actions[0])\n","        rewards = torch.tensor([reward], device=device)\n","        dones = torch.tensor([done], device=device)\n","\n","        state_list.append(states.unsqueeze(0))\n","        prob_list.append(log_probs.unsqueeze(0))\n","        action_list.append(actions.unsqueeze(0))\n","        reward_list.append(rewards.unsqueeze(0))\n","        value_list.append(values.unsqueeze(0))\n","        done_list.append(dones)\n","\n","        if np.any(dones.cpu().numpy()):\n","            ten_rewards += reward\n","            i_episode += 1\n","            state = envs.reset()\n","            if i_episode%10 == 0:\n","                # writer.add_scalar('ten episodes average rewards', ten_rewards/10.0, i_episode)\n","                ten_rewards = 0\n","\n","    state_list = torch.cat(state_list, dim=0)\n","    prob_list = torch.cat(prob_list, dim=0)\n","    action_list = torch.cat(action_list, dim=0)\n","    reward_list = torch.cat(reward_list, dim=0)\n","    value_list = torch.cat(value_list, dim=0)\n","    done_list = torch.cat(done_list, dim=0)\n","    return prob_list, state_list, action_list, reward_list, value_list, done_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2uHlMf6Jh6P"},"outputs":[],"source":["def calc_returns(rewards, values, dones):\n","    n_step = len(rewards)\n","    n_agent = len(rewards[0])\n","\n","    # Create empty buffer\n","    GAE = torch.zeros(n_step,n_agent).float().to(device)\n","    returns = torch.zeros(n_step,n_agent).float().to(device)\n","\n","    # Set start values\n","    GAE_current = torch.zeros(n_agent).float().to(device)\n","\n","    TAU = 0.95\n","    discount = 0.99\n","    values_next = values[-1].detach()\n","    returns_current = values[-1].detach()\n","    for irow in reversed(range(n_step)):\n","        values_current = values[irow]\n","        rewards_current = rewards[irow]\n","        gamma = discount * (1. - dones[irow].float())\n","\n","        # Calculate TD Error\n","        td_error = rewards_current + gamma * values_next - values_current\n","        # Update GAE, returns\n","        GAE_current = td_error + gamma * TAU * GAE_current\n","        returns_current = rewards_current + gamma * returns_current\n","        # Set GAE, returns to buffer\n","        GAE[irow] = GAE_current\n","        returns[irow] = returns_current\n","\n","        values_next = values_current\n","\n","    return GAE, returns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ky5-kOu7Jh6P"},"outputs":[],"source":["def eval_policy(envs, policy, tmax=1000):\n","    reward_list=[]\n","    state = envs.reset()\n","    for t in range(tmax):\n","        states = get_screen()\n","        action_est, values = policy(states)\n","        sigma = nn.Parameter(torch.zeros(action_size))\n","        dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n","        actions = dist.sample()\n","        _, reward, done, _  = envs.step(actions[0])\n","        dones = done\n","        reward_list.append(np.mean(reward))\n","\n","        # stop if any of the trajectories is done to have retangular lists\n","        if np.any(dones):\n","            break\n","    return reward_list"]},{"cell_type":"markdown","metadata":{"id":"bgOWQeRPJh6Q"},"source":["## Network Architecture\n","An actor-critic structure with continuous action space is used for this project. The policy consists of 3 parts, a shared hidden layers, actor, and critic.\n","The actor layer outputs the mean value of a normal distribution, from which the agent's action is sampled. The critic layer yields the value function.\n","\n","- Shared layer:\n","```\n","Input State(48,48,3) -> Conv2d(3, 16, 5, 2) -> BatchNorm2d(16) -> Conv2d(16, 32, 5, 2)-> BatchNorm2d(32)\n","-> Conv2d(32, 32, 5, 2) -> BatchNorm2d(32) -> Dense(128) -> LeakyReLU -> Dense(128) -> LeakyReLU -> Dense(64) -> LeakyReLU\n","```\n","- Actor and Critic layers:\n","```\n","LeakyRelu -> Dense(64) -> LeakyRelu -> Dense(4)-> tanh -> Actor's output\n","LeakyReLU -> Dense(64) -> LeakyRelu -> Dense(1) -> Critic's output\n","```\n","\n","### Model update using PPO/GAE\n","The hyperparameters used during training are:\n","\n","Parameter | Value | Description\n","------------ | ------------- | -------------\n","Number of Agents | 1 | Number of agents trained simultaneously\n","tmax | 20 | Maximum number of steps per episode\n","Epochs | 10 | Number of training epoch per batch sampling\n","Batch size | 128 | Size of batch taken from the accumulated  trajectories\n","Discount (gamma) | 0.993 | Discount rate\n","Epsilon | 0.07 | Ratio used to clip r = new_probs/old_probs during training\n","Gradient clip | 10.0 | Maximum gradient norm\n","Beta | 0.01 | Entropy coefficient\n","Tau | 0.95 | tau coefficient in GAE\n","Learning rate | 2e-4 | Learning rate\n","Optimizer | Adam | Optimization method\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"br_uXu4qJh6Q"},"outputs":[],"source":["# run your own policy!\n","policy=ActorCritic(state_size=(screen_height, screen_width),\n","              action_size=action_size,\n","              shared_layers=[128, 64],\n","              critic_hidden_layers=[64],\n","              actor_hidden_layers=[64],\n","              init_type='xavier-uniform',\n","              seed=0).to(device)\n","\n","# we use the adam optimizer with learning rate 2e-4\n","# optim.SGD is also possible\n","optimizer = optim.Adam(policy.parameters(), lr=2e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNKPcouMJh6R"},"outputs":[],"source":["PATH = os.path.join(write_to, f'ppo_model_{time.strftime(\"%Y%m%d-%H%M%S\")}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdWtdGRdJh6S","scrolled":true,"executionInfo":{"status":"ok","timestamp":1731711036921,"user_tz":300,"elapsed":3254198,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"}},"outputId":"f054b5cb-0f35-4f21-857f-68ebfebed0ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Environment solved in 26 seasons!\tAverage Score: 52.77\n","Average Score: 52.77\n","Elapsed time: 2:47:30.541057\n"]}],"source":["best_mean_reward = None\n","\n","scores_window = deque(maxlen=100)  # last 100 scores\n","\n","discount = 0.993\n","epsilon = 0.07\n","beta = .01\n","opt_epoch = 10\n","season = 1000000\n","batch_size = 128\n","tmax = 1000 #env episode steps\n","save_scores = []\n","start_time = timeit.default_timer()\n","\n","for s in range(season):\n","    policy.eval()\n","    old_probs_lst, states_lst, actions_lst, rewards_lst, values_lst, dones_list = collect_trajectories(envs=env, policy=policy, tmax=tmax, nrand = 5)\n","\n","    season_score = rewards_lst.sum(dim=0).item()\n","    scores_window.append(season_score)\n","    save_scores.append(season_score)\n","\n","    gea, target_value = calc_returns(rewards = rewards_lst, values = values_lst, dones=dones_list)\n","    gea = (gea - gea.mean()) / (gea.std() + 1e-8)\n","\n","    policy.train()\n","\n","    # cat all agents\n","    def concat_all(v):\n","        #print(v.shape)\n","        if len(v.shape) == 3:#actions\n","            return v.reshape([-1, v.shape[-1]])\n","        if len(v.shape) == 5:#states\n","            v = v.reshape([-1, v.shape[-3], v.shape[-2],v.shape[-1]])\n","            #print(v.shape)\n","            return v\n","        return v.reshape([-1])\n","\n","    old_probs_lst = concat_all(old_probs_lst)\n","    states_lst = concat_all(states_lst)\n","    actions_lst = concat_all(actions_lst)\n","    rewards_lst = concat_all(rewards_lst)\n","    values_lst = concat_all(values_lst)\n","    gea = concat_all(gea)\n","    target_value = concat_all(target_value)\n","\n","    # gradient ascent step\n","    n_sample = len(old_probs_lst)//batch_size\n","    idx = np.arange(len(old_probs_lst))\n","    np.random.shuffle(idx)\n","\n","    epoch_clip_loss = 0\n","    epoch_value_loss = 0\n","    epoch_entropy = 0\n","    epoch_total_loss = 0\n","\n","    for epoch in range(opt_epoch):\n","        for b in range(n_sample):\n","            ind = idx[b*batch_size:(b+1)*batch_size]\n","            g = gea[ind]\n","            tv = target_value[ind]\n","            actions = actions_lst[ind]\n","            old_probs = old_probs_lst[ind]\n","\n","            action_est, values = policy(states_lst[ind])\n","            sigma = nn.Parameter(torch.zeros(action_size))\n","            dist = torch.distributions.Normal(action_est, F.softplus(sigma).to(device))\n","            log_probs = dist.log_prob(actions)\n","            log_probs = torch.sum(log_probs, dim=-1)\n","            entropy = torch.sum(dist.entropy(), dim=-1)\n","\n","            ratio = torch.exp(log_probs - old_probs)\n","            ratio_clipped = torch.clamp(ratio, 1 - epsilon, 1 + epsilon)\n","            L_CLIP = torch.mean(torch.min(ratio*g, ratio_clipped*g))\n","            # entropy bonus\n","            S = entropy.mean()\n","            # squared-error value function loss\n","            L_VF = 0.5 * (tv - values).pow(2).mean()\n","            # clipped surrogate\n","            L = -(L_CLIP - L_VF + beta*S)\n","\n","            optimizer.zero_grad()\n","            # This may need retain_graph=True on the backward pass\n","            # as pytorch automatically frees the computational graph after\n","            # the backward pass to save memory\n","            # Without this, the chain of derivative may get lost\n","            L.backward(retain_graph=True)\n","            torch.nn.utils.clip_grad_norm_(policy.parameters(), 10.0)\n","            optimizer.step()\n","\n","            epoch_clip_loss += L_CLIP.item()\n","            epoch_value_loss += L_VF.item()\n","            epoch_entropy += S.item()\n","            epoch_total_loss += L.item()\n","\n","            del(L)\n","\n","    # calculate average losses\n","    avg_clip_loss = epoch_clip_loss / (opt_epoch * n_sample)\n","    avg_value_loss = epoch_value_loss / (opt_epoch * n_sample)\n","    avg_entropy = epoch_entropy / (opt_epoch * n_sample)\n","    avg_total_loss = epoch_total_loss / (opt_epoch * n_sample)\n","\n","    # the clipping parameter reduces as time goes on\n","    epsilon*=.999\n","\n","    # the regulation term also reduces\n","    # this reduces exploration in later runs\n","    beta*=.998\n","\n","    mean_reward = np.mean(scores_window)\n","\n","    # log metrics\n","    log_metrics(s, season_score, mean_reward, epsilon, beta, avg_clip_loss, avg_value_loss, avg_entropy, avg_total_loss)\n","\n","    # display some progress every n iterations\n","    if best_mean_reward is None or best_mean_reward < mean_reward:\n","        # For saving the model and possibly resuming training\n","        torch.save({\n","                'policy_state_dict': policy.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'epsilon': epsilon,\n","                'beta': beta\n","                }, PATH)\n","        if best_mean_reward is not None:\n","            print(\"Best mean reward updated %.3f -> %.3f, model saved\" % (best_mean_reward, mean_reward))\n","        best_mean_reward = mean_reward\n","\n","    if s>=25 and mean_reward>50:\n","        print('Environment solved in {:d} seasons!\\tAverage Score: {:.2f}'.format(s+1, mean_reward))\n","        break\n","\n","print('Average Score: {:.2f}'.format(mean_reward))\n","elapsed = timeit.default_timer() - start_time\n","print(\"Elapsed time: {}\".format(timedelta(seconds=elapsed)))\n","# writer.close()\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"JAAJ8cwlJh6T"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jm1A2-bQJh6T","executionInfo":{"status":"error","timestamp":1731711036930,"user_tz":300,"elapsed":26,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"}},"colab":{"base_uri":"https://localhost:8080/","height":411},"outputId":"f6c5e731-a200-418a-b5f6-f993197e1879"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-8dc3eb665426>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(PATH)\n"]},{"output_type":"error","ename":"error","evalue":"Not connected to physics server.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-8dc3eb665426>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Episode: {0:d}, reward: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-dc2df1955095>\u001b[0m in \u001b[0;36meval_policy\u001b[0;34m(envs, policy, tmax)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mreward_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetPhysicsEngineParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumSolverIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetTimeStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: Not connected to physics server."]}],"source":["episode = 10\n","scores_window = deque(maxlen=100)  # last 100 scores\n","env = KukaDiverseObjectEnv(renders=False, isDiscrete=False, removeHeightHack=False, maxSteps=20, isTest=True)\n","env.cid = p.connect(p.DIRECT)\n","# load the model\n","checkpoint = torch.load(PATH)\n","policy.load_state_dict(checkpoint['policy_state_dict'])\n","\n","# evaluate the model\n","for e in range(episode):\n","    rewards = eval_policy(envs=env, policy=policy)\n","    reward = np.sum(rewards,0)\n","    print(\"Episode: {0:d}, reward: {1}\".format(e+1, reward), end=\"\\n\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}